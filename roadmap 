# Complete gRPC Performance Analysis Guide
## Spring Boot REST API → Quarkus gRPC → PostgreSQL

### 1. gRPC Connection Reuse Analysis

#### A. Connection Pooling Investigation
**What to Check:**
- gRPC channels are expensive to create and should be reused
- Spring Boot gRPC client configuration for connection pooling
- Channel lifecycle management

**Implementation Analysis:**

```java
// Spring Boot gRPC Client Configuration
@Configuration
public class GrpcClientConfig {
    
    @Bean
    public NettyGrpcChannelFactory grpcChannelFactory() {
        return NettyGrpcChannelFactory.sharedInstance();
    }
    
    // Check if you're using singleton channel
    @Bean
    public ManagedChannel grpcChannel() {
        return ManagedChannelBuilder.forAddress("localhost", 9090)
            .keepAliveTime(30, TimeUnit.SECONDS)
            .keepAliveTimeout(5, TimeUnit.SECONDS)
            .keepAliveWithoutCalls(true)
            .usePlaintext()
            .build();
    }
}
```

**Testing Approach:**
```bash
# Monitor connection count
netstat -an | grep :9090 | wc -l

# Use tcpdump to monitor connection establishment
sudo tcpdump -i any -n port 9090

# Monitor with ss command
ss -tuln | grep :9090
```

#### B. Connection Reuse Verification
**Tools to Use:**
- **Wireshark/tcpdump**: Monitor TCP connection establishment
- **JVM metrics**: Track connection pool statistics
- **Application logs**: Enable gRPC debug logging

```yaml
# application.yml - Enable gRPC debug logging
logging:
  level:
    io.grpc: DEBUG
    io.grpc.netty: DEBUG
```

### 2. Connection Reset Handling

#### A. Automatic Reconnection Behavior
**gRPC Client Resilience Configuration:**

```java
@Service
public class GrpcClientService {
    
    private final ManagedChannel channel;
    private final YourServiceGrpc.YourServiceBlockingStub stub;
    
    public GrpcClientService() {
        this.channel = ManagedChannelBuilder.forAddress("quarkus-grpc-host", 9090)
            // Retry configuration
            .enableRetry()
            .maxRetryAttempts(3)
            // Keep alive settings
            .keepAliveTime(30, TimeUnit.SECONDS)
            .keepAliveTimeout(5, TimeUnit.SECONDS)
            .keepAliveWithoutCalls(true)
            .build();
            
        this.stub = YourServiceGrpc.newBlockingStub(channel);
    }
    
    // Implement retry logic with exponential backoff
    public ResponseType callWithRetry(RequestType request) {
        return Failsafe.with(RetryPolicy.<ResponseType>builder()
            .handle(StatusRuntimeException.class)
            .withDelay(Duration.ofSeconds(1))
            .withMaxRetries(3)
            .build())
            .get(() -> stub.yourMethod(request));
    }
}
```

#### B. Connection Reset Testing
**Simulation Methods:**
```bash
# Simulate network interruption
sudo iptables -A INPUT -p tcp --dport 9090 -j DROP
# Remove after testing
sudo iptables -D INPUT -p tcp --dport 9090 -j DROP

# Restart Quarkus service
docker restart quarkus-grpc-service

# Monitor reconnection behavior
tail -f application.log | grep -i "grpc\|connection"
```

### 3. Keep-Alive Configuration

#### A. Spring Boot gRPC Client Keep-Alive
```java
@Configuration
public class GrpcKeepAliveConfig {
    
    @Bean
    public ManagedChannel grpcChannel() {
        return ManagedChannelBuilder.forAddress("quarkus-host", 9090)
            // Keep-alive settings
            .keepAliveTime(30, TimeUnit.SECONDS)        // Send keep-alive every 30s
            .keepAliveTimeout(5, TimeUnit.SECONDS)      // Wait 5s for keep-alive response
            .keepAliveWithoutCalls(true)                // Send keep-alive even without active calls
            .maxInboundMessageSize(4 * 1024 * 1024)     // 4MB max message size
            .build();
    }
}
```

#### B. Quarkus gRPC Server Keep-Alive
```yaml
# application.properties in Quarkus
quarkus.grpc.server.keep-alive-time=30s
quarkus.grpc.server.keep-alive-timeout=5s
quarkus.grpc.server.permit-keep-alive-without-calls=true
quarkus.grpc.server.permit-keep-alive-time=10s
```

#### C. Network-Level Keep-Alive
```yaml
# Spring Boot application.yml
server:
  tomcat:
    connection-timeout: 60000
    keep-alive-timeout: 60000
    
# System-level TCP keep-alive (Linux)
# /etc/sysctl.conf
net.ipv4.tcp_keepalive_time = 600
net.ipv4.tcp_keepalive_intvl = 60
net.ipv4.tcp_keepalive_probes = 3
```

### 4. Memory and CPU Usage Patterns

#### A. Monitoring Setup
**JVM Metrics Collection:**

```java
// Spring Boot Actuator + Micrometer
@Configuration
public class MetricsConfig {
    
    @Bean
    public MeterRegistry meterRegistry() {
        return new PrometheusMeterRegistry(PrometheusConfig.DEFAULT);
    }
    
    // Custom gRPC metrics
    @Bean
    public TimedAspect timedAspect(MeterRegistry registry) {
        return new TimedAspect(registry);
    }
}

// Add to service methods
@Timed(name = "grpc.call.duration", description = "gRPC call duration")
public ResponseType callGrpcService(RequestType request) {
    // gRPC call implementation
}
```

**Memory Analysis Tools:**
```bash
# JVM memory monitoring
jstat -gc -t <pid> 1s

# Heap dump analysis
jmap -dump:format=b,file=heapdump.hprof <pid>

# Memory usage over time
jstat -gccapacity <pid>

# CPU profiling
java -XX:+FlightRecorder -XX:StartFlightRecording=duration=60s,filename=profile.jfr YourApp
```

#### B. Memory Pattern Analysis
**Key Metrics to Monitor:**
- Heap usage patterns during gRPC calls
- Off-heap memory (direct buffers used by Netty)
- Connection pool memory consumption
- Garbage collection frequency and duration

```yaml
# JVM tuning for gRPC applications
JAVA_OPTS: >
  -Xms512m -Xmx2g
  -XX:MaxDirectMemorySize=512m
  -XX:+UseG1GC
  -XX:MaxGCPauseMillis=200
  -XX:+PrintGCDetails
  -XX:+PrintGCTimeStamps
```

### 5. API Throughput Analysis

#### A. Load Testing Setup
**JMeter Configuration:**
```xml
<!-- JMeter Test Plan for REST API -->
<TestPlan>
  <ThreadGroup num_threads="100" ramp_time="10" duration="300">
    <HTTPSamplerProxy>
      <stringProp name="HTTPSampler.domain">localhost</stringProp>
      <stringProp name="HTTPSampler.port">8080</stringProp>
      <stringProp name="HTTPSampler.path">/api/your-endpoint</stringProp>
      <stringProp name="HTTPSampler.method">POST</stringProp>
    </HTTPSamplerProxy>
  </ThreadGroup>
</TestPlan>
```

**Gatling Load Test:**
```scala
class GrpcLoadTest extends Simulation {
  
  val httpProtocol = http
    .baseUrl("http://localhost:8080")
    .acceptHeader("application/json")
    .contentTypeHeader("application/json")
  
  val scn = scenario("gRPC API Load Test")
    .exec(http("create_request")
      .post("/api/your-endpoint")
      .body(StringBody("""{"key": "value"}"""))
      .check(status.is(200)))
  
  setUp(
    scn.inject(
      incrementUsersPerSec(10)
        .times(5)
        .eachLevelLasting(30 seconds)
        .separatedByRampsLasting(10 seconds)
        .startingFrom(10)
    )
  ).protocols(httpProtocol)
}
```

#### B. Throughput Monitoring
```java
// Custom metrics for throughput tracking
@Component
public class ThroughputMetrics {
    
    private final Counter requestCounter;
    private final Timer responseTimer;
    
    public ThroughputMetrics(MeterRegistry registry) {
        this.requestCounter = Counter.builder("api.requests.total")
            .description("Total API requests")
            .register(registry);
            
        this.responseTimer = Timer.builder("api.response.time")
            .description("API response time")
            .register(registry);
    }
    
    public void recordRequest() {
        requestCounter.increment();
    }
    
    public Timer.Sample startTimer() {
        return Timer.start(responseTimer);
    }
}
```

### 6. Latency Analysis

#### A. End-to-End Latency Tracking
```java
@RestController
public class ApiController {
    
    @Autowired
    private GrpcClientService grpcService;
    
    @PostMapping("/api/data")
    @Timed(name = "api.endpoint.duration", description = "API endpoint duration")
    public ResponseEntity<String> processData(@RequestBody DataRequest request) {
        long startTime = System.nanoTime();
        
        try {
            // gRPC call with timing
            Timer.Sample grpcTimer = Timer.start();
            GrpcResponse response = grpcService.callGrpcService(request);
            grpcTimer.stop(Timer.builder("grpc.call.duration").register(meterRegistry));
            
            long endTime = System.nanoTime();
            long totalLatency = (endTime - startTime) / 1_000_000; // Convert to ms
            
            // Log latency metrics
            log.info("Total latency: {}ms", totalLatency);
            
            return ResponseEntity.ok("Success");
        } catch (Exception e) {
            log.error("Error processing request", e);
            return ResponseEntity.status(500).body("Error");
        }
    }
}
```

#### B. gRPC-Specific Latency Monitoring
```java
// gRPC interceptor for latency tracking
public class LatencyInterceptor implements ClientInterceptor {
    
    @Override
    public <ReqT, RespT> ClientCall<ReqT, RespT> interceptCall(
            MethodDescriptor<ReqT, RespT> method, CallOptions callOptions, Channel next) {
        
        return new SimpleForwardingClientCall<ReqT, RespT>(next.newCall(method, callOptions)) {
            @Override
            public void start(Listener<RespT> responseListener, Metadata headers) {
                long startTime = System.nanoTime();
                
                super.start(new SimpleForwardingClientCallListener<RespT>(responseListener) {
                    @Override
                    public void onClose(Status status, Metadata trailers) {
                        long duration = System.nanoTime() - startTime;
                        // Record latency metrics
                        Metrics.timer("grpc.call.latency", "method", method.getFullMethodName())
                            .record(duration, TimeUnit.NANOSECONDS);
                        super.onClose(status, trailers);
                    }
                }, headers);
            }
        };
    }
}
```

### 7. Maximum TPS (Transactions Per Second)

#### A. TPS Testing Strategy
**Baseline Testing:**
```bash
# Use Apache Bench for quick TPS testing
ab -n 10000 -c 100 -T 'application/json' -p payload.json http://localhost:8080/api/endpoint

# Use wrk for more advanced testing
wrk -t12 -c400 -d30s --script=post.lua http://localhost:8080/api/endpoint
```

**wrk Script (post.lua):**
```lua
wrk.method = "POST"
wrk.body = '{"key": "value", "data": "test"}'
wrk.headers["Content-Type"] = "application/json"
```

#### B. TPS Optimization Configuration
```yaml
# Spring Boot optimization for high TPS
server:
  tomcat:
    threads:
      max: 200
      min-spare: 10
    max-connections: 8192
    accept-count: 100
    connection-timeout: 20000

# Quarkus optimization
quarkus:
  vertx:
    event-loops-pool-size: 8
    worker-pool-size: 20
  grpc:
    server:
      max-inbound-message-size: 4194304
      max-inbound-metadata-size: 8192
```

#### C. Database Connection Pool Tuning
```yaml
# HikariCP configuration for high TPS
spring:
  datasource:
    hikari:
      maximum-pool-size: 20
      minimum-idle: 5
      connection-timeout: 30000
      idle-timeout: 600000
      max-lifetime: 1800000
      leak-detection-threshold: 60000
```

### 8. Azure Key Vault Integration

#### A. Spring Boot Azure Key Vault Setup
```xml
<!-- pom.xml dependencies -->
<dependency>
    <groupId>com.azure.spring</groupId>
    <artifactId>spring-cloud-azure-starter-keyvault-secrets</artifactId>
    <version>4.15.0</version>
</dependency>
```

```yaml
# application.yml
spring:
  cloud:
    azure:
      keyvault:
        secret:
          enabled: true
          endpoint: https://your-keyvault.vault.azure.net/
          property-sources:
            - endpoint: https://your-keyvault.vault.azure.net/
              name: your-keyvault
              
azure:
  keyvault:
    uri: https://your-keyvault.vault.azure.net/
    client-id: ${AZURE_CLIENT_ID}
    client-secret: ${AZURE_CLIENT_SECRET}
    tenant-id: ${AZURE_TENANT_ID}
```

#### B. Quarkus Azure Key Vault Integration
```xml
<!-- pom.xml -->
<dependency>
    <groupId>io.quarkus</groupId>
    <artifactId>quarkus-azure-keyvault</artifactId>
</dependency>
```

```properties
# application.properties
quarkus.vault.url=https://your-keyvault.vault.azure.net/
quarkus.vault.authentication.client-id=${AZURE_CLIENT_ID}
quarkus.vault.authentication.client-secret=${AZURE_CLIENT_SECRET}
quarkus.vault.authentication.tenant-id=${AZURE_TENANT_ID}

# Database credentials from Key Vault
%prod.quarkus.datasource.username=${vault.database-username}
%prod.quarkus.datasource.password=${vault.database-password}
```

#### C. Performance Impact Analysis
```java
// Monitor Key Vault call latency
@Component
public class KeyVaultMetrics {
    
    private final Timer keyVaultTimer;
    
    public KeyVaultMetrics(MeterRegistry registry) {
        this.keyVaultTimer = Timer.builder("keyvault.call.duration")
            .description("Key Vault call duration")
            .register(registry);
    }
    
    @EventListener
    public void onKeyVaultAccess(KeyVaultAccessEvent event) {
        keyVaultTimer.record(event.getDuration(), TimeUnit.MILLISECONDS);
    }
}
```

## Testing and Monitoring Approach

### Phase 1: Baseline Establishment (Week 1)
1. Set up monitoring infrastructure (Prometheus + Grafana)
2. Implement custom metrics collection
3. Establish baseline performance metrics
4. Document current configuration

### Phase 2: Connection Analysis (Week 2)
1. Monitor gRPC connection behavior
2. Test connection reset scenarios
3. Optimize keep-alive settings
4. Validate connection pooling

### Phase 3: Performance Testing (Week 3)
1. Conduct load testing with increasing TPS
2. Monitor memory and CPU patterns
3. Identify bottlenecks and optimization opportunities
4. Test Azure Key Vault integration impact

### Phase 4: Optimization (Week 4)
1. Implement identified optimizations
2. Re-run performance tests
3. Document final configuration
4. Create monitoring dashboards

## Key Performance Indicators (KPIs)

### Primary Metrics
- **API Response Time**: < 500ms (95th percentile)
- **gRPC Call Latency**: < 100ms (95th percentile)
- **Maximum TPS**: Target based on load requirements
- **Error Rate**: < 0.1%

### Secondary Metrics
- **Memory Usage**: Stable heap usage patterns
- **CPU Utilization**: < 70% under normal load
- **Connection Pool Utilization**: < 80%
- **Database Response Time**: < 50ms (95th percentile)

## Recommended Tools Stack

### Monitoring and Observability
- **Application Metrics**: Micrometer + Prometheus
- **Dashboards**: Grafana
- **Distributed Tracing**: Jaeger or Zipkin
- **Log Aggregation**: ELK Stack

### Load Testing
- **API Testing**: JMeter or Gatling
- **gRPC Testing**: ghz (gRPC load testing tool)
- **Database Testing**: pgbench for PostgreSQL

### Profiling and Analysis
- **JVM Profiling**: JProfiler or VisualVM
- **Network Analysis**: Wireshark or tcpdump
- **Database Monitoring**: pgAdmin or DataDog

This comprehensive approach will give you detailed insights into all aspects of your gRPC-based architecture performance.